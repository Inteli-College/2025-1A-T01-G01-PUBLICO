# Module 3 - Testing Application

## Introduction

This project is part of a scientific research initiative focused on improving nonverbal communication for autistic children through the use of Artificial Intelligence (AI) within Augmentative and Alternative Communication (AAC) methodologies. The objective is to develop a system capable of generating pictograms and short stories from cartoons and drawing photos, assisting children in expressing themselves more effectively in educational and therapeutic environments.

In this phase, a new open-source multimodal model, **LLaVA Next**, was applied to ensure reproducibility and transparency for future academic replication. In parallel, the **Gemini API** was integrated due to its free-tier availability and better performance when handling large datasets, optimizing both the generation process and the projectâ€™s scalability.

---

## Development

The development process was guided by iterative experimentation and a focus on accessibility and scalability. From the beginning, the application was structured with a clear technical foundation that balanced performance, reproducibility, and ethical requirements.

The **backend** was built using **FastAPI**, containerized with **Docker**, and deployed through **Google Cloud Run**. This setup enabled automatic scaling, allowing the application to run on demand with no idle cost. The **frontend**, developed in **React**, was deployed via **Vercel**, providing a reliable and fast environment for user interaction and testing. Together, these services created a fully cloud-native ecosystem supported by **US$300 in Google Cloud academic credits**, ensuring operational sustainability during the research phase.

Data management was handled through **PostgreSQL (Neon Database)** for structured information and **Google Cloud Storage (GCS)** for storing images and media generated by users. The architecture was designed to maintain data integrity and security while allowing efficient access for AI processing.

Authentication was introduced early in the development cycle to ensure data protection and controlled access. Each user can create a personal account with **email and password**, with sessions authenticated through **JWT (JSON Web Token)**, valid for two hours. This approach aligns with the ethical standards of research involving sensitive data.

Once the infrastructure was stable, experimentation with AI models began. The **LLaVA Next** model was adopted as the core open-source alternative, enabling reproducibility in academic contexts, while the **Gemini API** was integrated for more efficient large-scale processing. Both were tested in generating pictograms and contextual stories based on cartoon and drawing inputs, forming the first multimodal results of the project.  

ðŸ”— [Access the application here](https://front-aac.vercel.app/login)

### Tools

| **Category** | **Tool / Technology** | **Purpose / Description** |
|---------------|------------------------|-----------------------------|
| **Frontend** | **React (Vite)** | User interface development and component management for the web application. |
| **Frontend Hosting** | **Vercel** | Continuous deployment and cloud hosting for the web interface. |
| **Backend** | **FastAPI (Python)** | RESTful API for handling requests, model integration, and business logic. |
| **Containerization** | **Docker** | Packaging and running the backend in isolated, reproducible environments. |
| **Backend Hosting** | **Google Cloud Run** | Serverless deployment of the API, ensuring scalability and cost efficiency. |
| **Database** | **PostgreSQL (Neon Database)** | Storage of structured user data. |
| **Cloud Storage** | **Google Cloud Storage (GCS)** | Management of images, generated stories, metadata from album, and user-uploaded media. |
| **AI Models** | **LLaVA Next** (open-source) & **Gemini API** (Google) | Multimodal AI for generating pictograms and textual narratives from images. |
| **Authentication** | **JWT (JSON Web Token)** | Secure session management for users (2-hour session window). |
| **Version Control** | **Git + GitHub** | Code versioning, collaboration, and deployment pipeline management. |
| **Environment Management** | **Python-dotenv / Google Cloud Secrets** | Secure configuration of environment variables and API keys. |
| **External API** | **ARASAAC API** | Retrieval of standardized pictograms used in AAC methodologies for consistent and inclusive communication. |

---

## Work Schedule

The project followed a structured schedule divided into five sprints, each with clear objectives and deliverables:

| **Sprint** | **Start Date** | **Main Activities** |
|-------------|----------------|----------------------|
| **Sprint 1** | 15/08 | Preparation of the detailed submission plan for the module, implementation of the authentication service, and revision of pending documents for the ethics committee. |
| **Sprint 2** | 29/08 | Creation of a drawing database, integration with the **LLaVA Next model**, comparison of results between **Gemini** and **LLaVA Next**, and deployment of the application with Gemini. |
| **Sprint 3** | 12/09 | Initial testing with therapists, collection of feedback, and adjustments to the application according to the results. |
| **Sprint 4** | 26/09 | Testing phase with children, compilation of results, and refinement of the user experience. *(Testing still pending due to ethical committee approval stage.)* |
| **Sprint 5** | 09/10 | Elaboration of the public report and preparation of the section with test results for publication. |

This schedule guided the development of the technological components, validation with professionals, and preparation for the next stage of ethical testing and field validation.

---

## Testing Phase and Preliminary Results

Initial testing was conducted with **speech therapists and educators** to assess usability and the semantic quality of the generated outputs. The project was disseminated to **USP**, **AACD**, and professionals experienced in working with autistic children to collect early feedback.

The initial results were **satisfactory**.  
Most of the **pictograms** generated were semantically coherent and contextually aligned with the input data, showing that the AI models successfully captured the intended meanings. However, the **stories** still presented narrative inconsistencies and required additional **prompt optimization** to enhance clarity and coherence.  

Professionals highlighted the **potential of the application** for therapeutic and educational use, suggesting interface simplifications to facilitate accessibility and integration into therapy sessions. Although direct testing sessions with children have not yet been conducted, communication with participating institutions is ongoing, and scheduling is currently in progress.

---

## Ethical Review and Compliance

The study has been submitted to the **Ethics Review Board**, but final approval has not yet been obtained due to continuous adjustments in the documentation. These modifications are necessary to ensure that the research fully complies with ethical requirements and reflects updates to the data handling and testing protocols. The submission remains under evaluation and will enable the next stage of testing with children once approved.

---

## Conclusion

The project demonstrates the potential of AI as a tool for assistive communication, combining innovation, accessibility, and social impact. The integration of **LLaVA Next** ensures reproducibility and transparency, while the use of **Gemini API** enhances processing efficiency and scalability within the scope of open research.

Preliminary testing indicates that the system effectively generates meaningful pictograms, though further refinement is required to improve the narrative coherence of the generated stories. The next steps involve prompt engineering adjustments, ethical approval completion, and structured testing sessions with children under professional supervision.

Through these continuous improvements, the research advances toward its primary goal: enabling nonverbal children to communicate more freely and independently through intelligent, human-centered technology.
